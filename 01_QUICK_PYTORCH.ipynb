{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b460933",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "- numpy가 지원하는 연산들을 GPU에서 할 수 있도록 함\n",
    "- 높은 성능과 유연성을 제공하는 딥러닝 지원\n",
    "\n",
    "> 따라서, numpy와 유사한 기능이 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0301e09",
   "metadata": {},
   "source": [
    "**pytorch 일반적인 import 형태**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab74eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566547d",
   "metadata": {},
   "source": [
    "**Tensor 생성**\n",
    "\n",
    "- Tensor는 numpy의 ndarray와 유사한 구조를 지님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da03c08",
   "metadata": {},
   "source": [
    "**scala (0D 텐서)**\n",
    "\n",
    "- scala 로 numpy 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7461cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 ()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data1 = np.array(10)\n",
    "print(data1, data1.ndim, data1.shape) # ndim은 axis축, shape은 행렬의 차원을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6687b0",
   "metadata": {},
   "source": [
    "**vector (1D 텐서)**\n",
    "\n",
    "- vector부터는 pytorch의 tensor로 만들 수 있음\n",
    "- shape은 torch.Size([3])과 같이 표현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb8bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.]) 1 torch.Size([2])\n",
      "tensor([0., 0., 0.]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.FloatTensor([1,2]) # 1,2 원소를 가진 1D 텐서를 선언\n",
    "print(data1, data1.ndim, data1.shape)\n",
    "\n",
    "data2 = torch.FloatTensor(3)\n",
    "print(data2, data2.ndim, data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7144d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]) 2 torch.Size([3, 2])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]]) 2 torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# matrix (2D 텐서)\n",
    "\n",
    "data3 = torch.FloatTensor(3,2)\n",
    "print(data3, data3.ndim, data3.shape)\n",
    "\n",
    "data4 = torch.FloatTensor([[1,2],[3,4],[5,6]])\n",
    "print(data4, data4.ndim, data4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f40bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.]]]) 3 torch.Size([3, 2, 1])\n",
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [6.]]]) 3 torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 3D 텐서\n",
    "\n",
    "data5 = torch.FloatTensor(3,2,1)\n",
    "print(data5, data5.ndim, data5.shape)\n",
    "\n",
    "data6 = torch.FloatTensor([[[1],[2]],[[3],[4]],[[5],[6]]])\n",
    "print(data6, data6.ndim, data6.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51bbaab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n",
      "tensor([[1., 2., 3.]]) 2 torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 밖에서부터 안쪽으로 텐서 선언의 이해\n",
    "data7 = torch.FloatTensor([[1],[2],[3]])\n",
    "print(data7, data7.ndim, data7.shape)\n",
    "\n",
    "data8 = torch.FloatTensor([[1,2,3]])\n",
    "print(data8, data8.ndim, data8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb5f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "tensor([[[0.5137, 0.7686, 0.8335],\n",
      "         [0.3950, 0.3086, 0.7261]],\n",
      "\n",
      "        [[0.0479, 0.6274, 0.7832],\n",
      "         [0.5850, 0.1909, 0.8901]]], dtype=torch.float16)\n",
      "tensor([[[[ 0.0811,  0.3062, -1.2355, -1.1281],\n",
      "          [-0.5444, -1.1448, -0.6339,  0.5816],\n",
      "          [-0.0259, -0.1619,  0.1930,  0.9442]],\n",
      "\n",
      "         [[-1.2119, -1.8076, -0.8704,  0.8878],\n",
      "          [-0.9709,  0.1472,  1.3055, -1.4564],\n",
      "          [-0.8289,  1.1651,  0.2112,  0.9574]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322, -0.0762,  1.2864,  1.1212],\n",
      "          [-0.9547,  0.6378, -0.6512, -0.2183],\n",
      "          [ 0.4214, -1.0205, -1.5117, -0.8665]],\n",
      "\n",
      "         [[ 0.4093,  1.1126,  0.4348,  0.4117],\n",
      "          [ 1.8167, -0.2309, -0.2957,  0.6260],\n",
      "          [-0.4418,  1.1247, -0.4216,  0.2126]]]])\n",
      "tensor([[10, 10, 10, 10],\n",
      "        [10, 10, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.zeros(3, dtype=torch.float)\n",
    "print(data1)\n",
    "data2 = torch.ones(2,2, dtype=torch.double)\n",
    "print(data2)\n",
    "data3 = torch.rand(2,2,3, dtype=torch.half)\n",
    "print(data3)\n",
    "data4 = torch.randn(2,2,3,4)\n",
    "print(data4)\n",
    "data5 = torch.full((2,4), 10)\n",
    "print(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be63d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([2, 2]) torch.Size([2, 2, 3]) torch.Size([2, 2, 3, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 형태 확인\n",
    "print(data1.shape, data2.shape, data3.shape, data4.shape, data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "116cdb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 2\n"
     ]
    }
   ],
   "source": [
    "# 배열의 차원을 나타냄\n",
    "print(data1.ndim, data2.ndim, data3.ndim, data4.ndim, data5.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea3d49b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float64 torch.float16 torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.dtype, data2.dtype, data3.dtype, data4.dtype, data5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffc8e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([2, 2]) torch.Size([2, 2, 3]) torch.Size([2, 2, 3, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 사이즈(원소 갯수) 확인\n",
    "# numpy와 달리 size가 아닌 size() 메서드 제공\n",
    "print(data1.size(), data2.size(), data3.size(), data4.size(), data5.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d3dae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "data6 = torch.FloatTensor([[1,2],[3,4]])\n",
    "data7 = torch.DoubleTensor([[1,2,3],[4,5,6]])\n",
    "data8 = torch.LongTensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "data9 = torch.FloatTensor(2,3,5)\n",
    "data10 = torch.DoubleTensor(3,3,2,4)\n",
    "data11 = torch.LongTensor(4,4)\n",
    "print(data11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1d59abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 10, 10, 10],\n",
      "        [10, 10, 10, 10]])\n",
      "tensor([[20, 20, 20, 20],\n",
      "        [20, 20, 20, 20]])\n"
     ]
    }
   ],
   "source": [
    "# _like()로 텐서 생성\n",
    "data12 = torch.full_like(data5, 20)\n",
    "\n",
    "print(data5)\n",
    "print(data12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b3e7f",
   "metadata": {},
   "source": [
    "**reshape() : 배열 구조 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3276b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3]) torch.Size([2, 3])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]], dtype=torch.float64) torch.Size([3, 2])\n",
      "tensor([[1., 2., 3., 4., 5., 6.]], dtype=torch.float64) torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.DoubleTensor([[1,2,3],[4,5,6]])\n",
    "print(data1, data1.size(), data1.shape)\n",
    "\n",
    "data1 = data1.reshape(3,2)\n",
    "print(data1, data1.shape)\n",
    "\n",
    "data1 = data1.reshape(1,-1) # -1은 열을 행의 갯수에 맞춰 자동 계산\n",
    "print(data1, data1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365c316",
   "metadata": {},
   "source": [
    "**view() : 텐서 구조 변경**\n",
    "\n",
    "- pytorch에서는 numpy처럼 reshape()로 배열 구조를 변경할 수 있지만, reshape() 보다는 view()메서드를 보다 많이 사용함\n",
    "- view()메서드는 reshape()랑 사용법 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1b53d",
   "metadata": {},
   "source": [
    "> 원소 수를 유지하면서 텐서의 크기를 변경할 때 많이 사용하며, 매우 중요함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "154e7509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) 높이(k) :  2 너비(n) :  2 깊이(m) :  3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.DoubleTensor([\n",
    "    [[1,2,3],\n",
    "    [4,5,6]],\n",
    "    [[7,8,9],\n",
    "     [10,11,12]]\n",
    "])\n",
    "\n",
    "print(data1.shape, \"높이(k) : \",data1.size(0), \"너비(n) : \",data1.size(1), \"깊이(m) : \",data1.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97b41699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]], dtype=torch.float64) torch.Size([2, 6])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]], dtype=torch.float64) torch.Size([4, 3])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]], dtype=torch.float64) torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "data1 = data1.view(2,-1) # (2,?) 으로 구성, -1은 자동 계산\n",
    "print(data1, data1.shape)\n",
    "\n",
    "data1 = data1.view(-1,3) # (?,3) 으로 구성\n",
    "print(data1, data1.shape)\n",
    "\n",
    "data1 = data1.view(3,2,-1) # (3,2,?) 으로 구성\n",
    "print(data1, data1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149b79d",
   "metadata": {},
   "source": [
    "**squeeze() : 텐서 차원 압축**\n",
    "\n",
    "- 차원이 1인 경우, 해당 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffcd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n",
      "tensor([1., 2., 3.]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1],[2],[3]])\n",
    "data2 = data1.squeeze()\n",
    "print(data1, data1.ndim, data1.shape)\n",
    "print(data2, data2.ndim, data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80a3826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8045,  0.3882, -0.7459, -0.4086],\n",
      "         [ 0.3001,  0.3762, -2.1080,  0.5432],\n",
      "         [ 0.2749, -2.0034,  0.6125, -0.3785]],\n",
      "\n",
      "        [[ 0.6988,  0.2892, -0.1220, -1.2459],\n",
      "         [-0.3011,  0.2599,  0.1605, -1.2743],\n",
      "         [ 0.1872, -0.4739, -0.6712,  0.2860]]]) 3 torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "data4 = torch.randn(2,1,3,4)\n",
    "data4 = data4.squeeze()\n",
    "print(data4, data4.ndim, data4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad055f2",
   "metadata": {},
   "source": [
    "**unsqueeze() : 특정 위치에 1인 차원을 추가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57ca9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) 2 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "print(data1, data1.ndim, data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a914bf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]]]) 3 torch.Size([1, 2, 3])\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.]],\n",
      "\n",
      "        [[4.],\n",
      "         [5.],\n",
      "         [6.]]]) 3 torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "data2 = data1.unsqueeze(0)\n",
    "data3 = data1.unsqueeze(2)\n",
    "\n",
    "print(data2, data2.ndim, data2.shape)\n",
    "print(data3, data3.ndim, data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2ec43",
   "metadata": {},
   "source": [
    "**데이터 타입 변환(type)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a44e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n",
      "torch.float16\n",
      "torch.float32\n",
      "torch.int32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.zeros(3, dtype=torch.float)\n",
    "print(data1.dtype)\n",
    "data2 = torch.ones(2,4, dtype=torch.double)\n",
    "print(data2.dtype)\n",
    "data3 = torch.rand(2,2,3, dtype=torch.half)\n",
    "print(data3.dtype)\n",
    "\n",
    "data1 = data1.type(dtype=torch.float32)\n",
    "data2 = data2.type(dtype=torch.int)\n",
    "data3 = data3.type(dtype=torch.double)\n",
    "\n",
    "print(data1.dtype)\n",
    "print(data2.dtype)\n",
    "print(data3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542733b0",
   "metadata": {},
   "source": [
    "**T: 전치(transpose) 행렬**\n",
    "- 행과 열을 교환하여 얻는 행렬을 의미 $A^T$ 로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "579bc24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(data2)\n",
    "data2 = data2.T\n",
    "print(data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fda89c",
   "metadata": {},
   "source": [
    "### numpy와 pytorch\n",
    "\n",
    "- Pytorch는 numpy의 ndarray를 GPU에서 실행시킬 수 있도록 개발되었으므르,\n",
    "- Pytorch의 tensor와 numpy의 ndarray는 서로 변환 가능\n",
    "- 이를 위해 Pytorch에서 다음 메서드를 제공\n",
    "    - 텐서객체.numpy(): tensor 객체를 numpy ndarray 객체로 변환\n",
    "    - torch.from_numpy(ndarray) : numpy의 ndarray를 tensor 객체로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1948b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) <class 'torch.Tensor'>\n",
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data1 = np.array([[1,2],[3,4]])\n",
    "print(data1, type(data1))\n",
    "\n",
    "data2 = torch.from_numpy(data1) # ndarray -> Tensor\n",
    "print(data2, type(data2))\n",
    "\n",
    "data3 = data2.numpy() # Tensor -> ndarray\n",
    "print(data3, type(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d158a",
   "metadata": {},
   "source": [
    "**arange() : 1차원 tensor 생성**\n",
    "\n",
    "- torch.arange(start, stop, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f0339e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5d3f2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c50cd09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b0b56",
   "metadata": {},
   "source": [
    "**linspace() : 범위 내 1차원 tensor 균등 생성**\n",
    "- torch.linspace(start, stop, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a88f75f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4444, 1.8889, 2.3333, 2.7778, 3.2222, 3.6667, 4.1111, 4.5556,\n",
       "        5.0000])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1,5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84348b09",
   "metadata": {},
   "source": [
    "**tensor 연산**\n",
    "\n",
    "- 본래 행렬 곱셈은 앞 행렬의 열의 갯수와 뒷 행렬의 행의 갯수가 같아야 행렬의 곱셈이 가능하지만,\n",
    "- tensor 연산은 shape가 동일해야 하고, 행과 열이 같은 값끼리 연산이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac114a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m data1 = torch.randn(\u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m      4\u001b[39m data2 = torch.randn(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdata1\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m  \u001b[38;5;66;03m# 오류 발생: shape 다름\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.randn(3, 2)\n",
    "data2 = torch.randn(2, 3)\n",
    "\n",
    "# data1 * data2  # 오류 발생: shape 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d04e8683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = torch.full((2,2),2)\n",
    "data2 = torch.full((2,2),3)\n",
    "data1 * data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86a1fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 3],\n",
      "        [3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 2]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.full((3,3),2)\n",
    "data2 = torch.full((3,3),1)\n",
    "\n",
    "print(data1 + data2)\n",
    "print(data1 - data2)\n",
    "print(data1 * data2)\n",
    "print(data1 / data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fbd70d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = torch.full((3,2),2)\n",
    "data2 = torch.full((2,3),1)\n",
    "torch.matmul(data1,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32a13fe4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata1\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(data1 * data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e7122",
   "metadata": {},
   "source": [
    "**Tensor연산 (브로드캐스팅)**\n",
    "- Tensor 간 연산이 broadcasting을 지원하며, Tensor는 동일한 차원으로 자동 확장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b7c45",
   "metadata": {},
   "source": [
    "**broadcasting 이해**\n",
    "- 둘 tensor 중 하나의 차원의 원소 수가 1이거나, 존재하지 않을 경우, broadcasting이 일어나면, 해당 차원이 확대됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b0b980fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3]) torch.Size([3, 3])\n",
      "tensor([[2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1],[2],[3]])\n",
    "data2 = torch.FloatTensor([1,1,1])\n",
    "data3 = data1 + data2\n",
    "\n",
    "print(data1.shape, data2.shape, data3.shape)\n",
    "print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58be181",
   "metadata": {},
   "source": [
    "**broadcasting 조건**\n",
    "- 두 tensor 간의 브로드캐스팅이 가능하기 위한 조건이 있음\n",
    "    - 두 tensor에 있는 각 차원에 대해, 끝쪽 차원부터 다음 조건을 비교하며, 앞쪽 방향으로 진행\n",
    "        - 각 차원의 원소 수가 똑같거나\n",
    "        - 둘 중의 하나의 차원의 원소 수는 1이거나, 존재하지 않을 경우\n",
    "\n",
    "- 주요 브로드캐스팅 기능 케이스를 broadcastable 이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce28c552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 4]) torch.Size([20, 4]) torch.Size([10, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(10,20,4)\n",
    "data2 = torch.FloatTensor(20,4)\n",
    "data3 = data1 + data2\n",
    "print(data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8798202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5]) torch.Size([10, 2, 1]) torch.Size([10, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(10,1,5)\n",
    "data2 = torch.FloatTensor(10,2,1)\n",
    "data3 = data1 + data2\n",
    "print(data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6cf0242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) torch.Size([10, 10, 1]) torch.Size([10, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor(5)\n",
    "data2 = torch.FloatTensor(10,10,1)\n",
    "data3 = data1 + data2\n",
    "print(data1.shape, data2.shape, data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a290a4",
   "metadata": {},
   "source": [
    "**tensor의 원소 접근 방법 (indexing)**\n",
    "- tensor의 특정 데이터를 가져오는 기능 indexing이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd95383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor(5.)\n",
      "tensor([2., 5.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "data3 = torch.FloatTensor([[1.,2.,3.],[4.,5.,6.]])\n",
    "print(data3)\n",
    "print(data3[1,1])\n",
    "print(data3[:,1]) # 슬라이싱, : 는 전체를 의미\n",
    "print(data3[:,:])\n",
    "print(data3[:1,:2]) # 슬라이싱, :1 이란 1 - 1인 0까지를 의미하므로, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dae0d6",
   "metadata": {},
   "source": [
    "**boolean indexing**\n",
    "- 조건 필터링과 검색을 동시에 할 수 있어서, 유용하게 쓰이는 인덱스 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bca133f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([5., 5., 5.])\n",
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[5,5,5]])\n",
    "data2 = data1 > 3\n",
    "\n",
    "print(data2)\n",
    "print(data1[data2])\n",
    "print(data1[(data1 > 3) & (data1 < 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd4350",
   "metadata": {},
   "source": [
    "**fancy indexing**\n",
    "- 다른 배열로 배열을 인덱싱할 수 있는 기능\n",
    "- 이를 통해, 복잡한 배열의 연속되지 않은 일부분을 빠르게 접근할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a59bd7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1797, -1.0917, -1.2264],\n",
       "        [ 1.9119,  1.9330, -0.7321],\n",
       "        [-1.7298,  0.4356,  1.4910],\n",
       "        [-0.3745,  0.0413,  1.3064]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = torch.randn(4,3)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0d5af71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9119,  1.9330, -0.7321],\n",
      "        [-1.7298,  0.4356,  1.4910],\n",
      "        [ 0.1797, -1.0917, -1.2264]])\n",
      "tensor([[ 1.9119,  1.9330, -0.7321],\n",
      "        [-0.3745,  0.0413,  1.3064]])\n"
     ]
    }
   ],
   "source": [
    "# 특정 행 배열 추출하기\n",
    "\n",
    "print(data1[[1,2,0]])\n",
    "print(data1[[1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "822f905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9119, -0.7321],\n",
      "        [-1.7298,  1.4910]])\n",
      "tensor([[ 1.9119],\n",
      "        [-0.3745]])\n"
     ]
    }
   ],
   "source": [
    "print(data1[[1,2]][:,[0,2]]) # 1,2 행을 선택하고 전체 행을 선택한 후 이 중에 0번째 열과 2번째 열만 추출하기\n",
    "print(data1[[1,-1]][:,[0]]) # 1,2 행을 선택하고 전체 행을 선택한 후 이 중에 0번째 열과 2번째 열만 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a46bb0",
   "metadata": {},
   "source": [
    "**텐서 복사: 텐서 객체.clone().detach()**\n",
    "- Pytorch 에서 tensor를 복사하는 다양한 방법이 존재하지만,\n",
    "- 이 중에서, 위 메서드를 사용하는 것이 가장 깔끔한 방법\n",
    "    - clone() : 기존 텐서객체의 내용을 복사한 텐서 생성\n",
    "    - detach() : 기존 텐서객체 그래프에서 분리된 텐서를 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f70a5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "print(data1)\n",
    "\n",
    "\n",
    "data2 = data1[:2,:2]\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [4., 4.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "data2[1,1] = 4\n",
    "print(data2)\n",
    "print(data1) # 얕은 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f4330eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 4.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "print(data1)\n",
    "\n",
    "data2 = data1[:2,:2].clone().detach() # .clone().detach() 로 복사하면 됨\n",
    "print(data2)\n",
    "\n",
    "data2[1,1] = 4\n",
    "print(data2)\n",
    "print(data1) # 깊은 복사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98d362",
   "metadata": {},
   "source": [
    "**tensor 조건 연산 : where()**\n",
    "- torch.where(조건 참일 때의 배열, 거짓일 때의 배열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "58fa54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 4]),)\n",
      "tensor([2., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([7,2,0,4,1])\n",
    "index = torch.where(data1 < 3) # 조건에 맞는 인덱스 번호 생성\n",
    "print(index)\n",
    "print(data1[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8c173",
   "metadata": {},
   "source": [
    "**조건에 맞는 값 특정 다른 값으로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eea4682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 2., 0., 4., 1.])\n",
      "tensor([ 1, -1, -1,  1, -1])\n"
     ]
    }
   ],
   "source": [
    "print(data1)\n",
    "data2 = torch.where(data1 < 3, -1, 1) # 조건에 맞으면 -1 틀리면 1으로 원소 값을 수정\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189784e",
   "metadata": {},
   "source": [
    "**다차원 배열에도 적용 가능**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "664ffac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1, -1,  1],\n",
      "        [ 1,  1,  1]])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "data2 = torch.where(data1 < 3, -1, 1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615c63f",
   "metadata": {},
   "source": [
    "**tensor 데이터 분석**\n",
    "- min(), max(), sum(), mean(), var(), std() : 최대값,최소값,합계값,평균값,분산값,표준편차값\n",
    "- argmin(), argmax() : 최소값의 인덱스 번호, 최대값의 인덱스 번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe5d5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(6.)\n",
      "tensor(21.)\n",
      "tensor(3.5000)\n",
      "tensor(3.5000)\n",
      "tensor(1.8708)\n",
      "tensor(0)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "print(data1.min())\n",
    "print(data1.max())\n",
    "print(data1.sum())\n",
    "print(data1.mean())\n",
    "print(data1.var())\n",
    "print(data1.std())\n",
    "print(data1.argmin())\n",
    "print(data1.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a752ab9",
   "metadata": {},
   "source": [
    "**텐서를 파일로 저장하고 불러오기**\n",
    "\n",
    "- 한 개의 텐서 저장\n",
    "    - save()로 파일 저장 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "41c9b703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.linspace(1,5,4)\n",
    "print(data1)\n",
    "torch.save(data1,\"mydata1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665517a",
   "metadata": {},
   "source": [
    "**한 개의 텐서 읽어오기**\n",
    "- load()로 파일로 저장된 1차원 배열을 읽어올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7216431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "data2 = torch.load('mydata1.pt')\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2e13a",
   "metadata": {},
   "source": [
    "**한 개 이상의 텐서 저장**\n",
    "- 각 배열을 key=배열 로 key 값을 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n",
      "tensor([ 1.,  4.,  7., 10.])\n",
      "tensor([  1.,  34.,  67., 100.])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.linspace(1,5,4)\n",
    "data2 = torch.linspace(1,10,4)\n",
    "data3 = torch.linspace(1,100,4)\n",
    "print(data1)\n",
    "print(data2)\n",
    "print(data3)\n",
    "\n",
    "datas = {'data1':data1,'data2':data2,'data3':data3}\n",
    "torch.save(datas,'mydata1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "40dded19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data1': tensor([1.0000, 2.3333, 3.6667, 5.0000]), 'data2': tensor([ 1.,  4.,  7., 10.]), 'data3': tensor([  1.,  34.,  67., 100.])}\n",
      "tensor([1.0000, 2.3333, 3.6667, 5.0000])\n",
      "tensor([ 1.,  4.,  7., 10.])\n",
      "tensor([  1.,  34.,  67., 100.])\n"
     ]
    }
   ],
   "source": [
    "datas = torch.load('mydata1.pt')\n",
    "print(datas)\n",
    "print(datas['data1'])\n",
    "print(datas['data2'])\n",
    "print(datas['data3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ec56e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(datas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
