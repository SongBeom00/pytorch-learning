{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42ea690",
   "metadata": {},
   "source": [
    "### Pytorch 모델 용어 정리 \n",
    "\n",
    "- 계층 (layer) : 모듈 또는 모듈을 구성하는 한 개의 계층을 의미함 (예 : 선형 계층, Linear Layer)\n",
    "\n",
    "- 모듈 (module) : 한 개 이상의 계층이 모여 구성된 것, 모듈이 모여서 새로운 모듈 구성 가능\n",
    "\n",
    "- 모델 (model) : 최종적인 네트워크 한 개의 모듈이 모델이 될 수도 있고, 여러 개의 모듈이 하나의 모델이 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f68bc6",
   "metadata": {},
   "source": [
    "### torch.nn과 nn.Module\n",
    "\n",
    "- torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소 제공\n",
    "\n",
    "- 모든 PyTorch 모듈은 nn.Module의 하위 클래스(subclass) 임\n",
    "\n",
    "- 모든 PyTorch 신경망 모델은 nn.Module 을 상속받은 하위 클래스로 정의함\n",
    "    - __init__에서 신경망 계층 초기화 필요\n",
    "    - forward() 메서드에서 입력 데이터에 대한 연산 정의 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948926e6",
   "metadata": {},
   "source": [
    "### Raw-level Linear Layer 구현\n",
    "\n",
    "- Linear Layer 이론, 수학적 이해, 실제 PyTorch의 필요 문법까지 익혔으므로,\n",
    "- 이를 기반으로 Linear Layer의 보다 선명한 이해 및 PyTorch에 익숙해지기 위해, Linear Layer를 가볍게 구현해보기로 함\n",
    "- 입력 차원이 4, 출력 차원이 3이고, Linear Layer 함수를 $f(x) = x * W + b$ 이라고 하면,\n",
    "- 다음과 같은 방식으로 계산되므로,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8bafbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.FloatTensor(4) # 입력\n",
    "W = torch.FloatTensor(4, 3) # 가중치\n",
    "b = torch.FloatTensor(3) # 편향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cff1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def linearfunction(x, W, b) :\n",
    "    y = torch.matmul(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23614a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([4, 3]) x torch.Size([4]) b torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(\"W\", W.shape, \"x\", x.shape, \"b\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1061dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "y = linearfunction(x, W, b)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de865887",
   "metadata": {},
   "source": [
    "### nn.Module 기반, Linear Layer 구현\n",
    "\n",
    "- 신경망 모델 클래스를 만들고, nn.Module 을 상속받음\n",
    "\n",
    "- __init__에서 신경망 계층 초기화 선언\n",
    "\n",
    "- forward() 메서드에서 입력 데이터에 대한 연산 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90c01903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        # __init__() 에서 신경망 계층 초기화\n",
    "        self.W = torch.FloatTensor(4,3)\n",
    "        self.b = torch.FloatTensor(3)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dcc1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(4)\n",
    "\n",
    "y = NeuralNetwork().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f5b2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "444a8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self, input_dim, output_dim) :\n",
    "        super().__init__()\n",
    "        # __init__() 에서 신경망 계층 초기화\n",
    "        self.W = torch.FloatTensor(input_dim, output_dim)\n",
    "        self.b = torch.FloatTensor(output_dim)\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28cea0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(4)\n",
    "\n",
    "mylinear = NeuralNetwork(4, 3)\n",
    "\n",
    "y = mylinear(x)\n",
    "\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd748aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in mylinear.parameters() :\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15c6acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self, input_dim, output_dim) :\n",
    "        super().__init__()\n",
    "        # __init__() 에서 신경망 계층 초기화\n",
    "        self.W = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "        self.b = nn.Parameter(torch.randn(output_dim))\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7477649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3569,  0.5765,  1.2102], grad_fn=<AddBackward0>) torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([[-1.8934,  0.6345, -0.7989],\n",
      "        [ 0.9339, -0.1070, -1.8543],\n",
      "        [ 0.8778, -0.8969,  1.1414],\n",
      "        [-1.5152,  1.0693, -0.5273]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3424, 0.4442, 0.9453], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4)\n",
    "\n",
    "mylinear = NeuralNetwork(4, 3)\n",
    "\n",
    "y = mylinear(x)\n",
    "\n",
    "print(y, y.shape)\n",
    "\n",
    "for param in mylinear.parameters() :\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d3106",
   "metadata": {},
   "source": [
    "### nn.Linear 클래스\n",
    "\n",
    "- 지금까지는 Linear Layer와 PyTorch 기반 신경망 모듈 구현 방법을 이해하기 위해, Linear Layer를 PyTorch 의 신경망 모듈 클래스로 구현해 본 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67235a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0730, 0.1868, 0.3002], grad_fn=<ViewBackward0>) torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.3998,  0.4187, -0.0150],\n",
      "        [ 0.0174, -0.1993,  0.3851, -0.0246],\n",
      "        [-0.4538,  0.2963,  0.1114, -0.2917]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0730, 0.1868, 0.3002], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mylinear = nn.Linear(4,3)\n",
    "\n",
    "y = mylinear(x)\n",
    "\n",
    "print(y, y.shape)\n",
    "\n",
    "for param in mylinear.parameters() :\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4750bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83fed9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0545,  0.0081, -0.3038], grad_fn=<ViewBackward0>) torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([[-0.2729,  0.4072,  0.0237, -0.3517],\n",
      "        [-0.3447,  0.0361, -0.3354,  0.3082],\n",
      "        [-0.3892,  0.1648, -0.0117,  0.2945]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0689,  0.4649, -0.2427], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4)\n",
    "\n",
    "mylinear = NeuralNetwork(4,3)\n",
    "y = mylinear(x)\n",
    "\n",
    "print(y, y.shape)\n",
    "\n",
    "for param in mylinear.parameters() :\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0b26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
